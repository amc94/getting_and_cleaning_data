mean(spop)
allsam
apply(allsam,1,mean)
mean(smeans)
sapply(flags, unique)
vapply(flags, unique, numeric(1))
ok()
sapply(flags,class)
vapply(flags, class, character(1))
?tapply
table(flags$landmass)
table(flags$animate)
tapply(flags$animate, flags$landmass, mean)
tapply(flags$population, flags$red, summary)
tapply(flags$population, flags$landmass, summary)
library(swirl)
swirl()
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mtdf)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tibble::as_tibble(mydf)
ok()
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select)cran,-time)
select(cran,-time)
select(cran, -(X:size))
-5:20
-(5:20)
select(cran, -(X:size))
filter(cran, package == "swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3,5,NA,10))
!is.na(c(3,5,NA,10))
filter(cran, !is.na(r_version))
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id)
)
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size/ 2^20)
mutate(cran3, size_mb = size/ 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size - 1000)
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
library("dplyr")
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?groub_by
?group_by
by_package <- group_by(cran, package)
by_package
summarize(cran, mean(size))
summarize(by_package, mean(size))
?n
?n
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack_sum, count > 679)
top_counts
View(top_counts)
top_counts_sorted <- arrange(top_counts, counts)
top_counts_sorted <- arrange(top_counts, count)
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
filter(pack_sum, unique > 465)
top_unique <- filter(pack_sum, unique > 465)
View(top_unique)
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
submit()
submit()
submit()
submit()
submit()
library(tidyr)
students
?gather
gather(students, sex, count, -grade)
students2
res <- gather(students2, key = "sex_class", value="count", -grade)
res <- gather(students2, key = sex_class, value=count, -grade)
res
?separate
separate(res, sex_class, c("sex", "class"))
submit()
student3
students3
submit()
submit()
?spread
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
library(readr)
parse_number("class5")
submit()
students4
submit()
submit()
submit()
passed
failed
passed <- mutate(passed, status="passed")
failed <- mutate(failed, status="failed")
bind_rows(passed, failed)
sat
?separate
submit()
sat %>%
select(-contains("total")) %>%
gather(key=part_sex, value=count, -score_range) %>% print
submit()
submit()
submit()
submit()
submit()
pwd()
dir()
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", "data/acs")
acs <- read.csv("data/acs")
library(dplyr)
agricultureLogical <- filter(acs, ACR == 3, AGS==6)
View(agricultureLogical)
which(agricultureLogical)
agricultureLogical <- (acs$ACR == 3 & acs$AGS==6)
which(agricultureLogical)
library(jpeg)
install.packages(jpeg)
install.package(jpeg)
install.packages("jpeg")
library(jpeg)
?jpeg
jpeg(https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg, native = TRUE)
jpeg("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg", native = TRUE)
jpeg("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg")
readJPEG("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg", native = TRUE)
readJPEG("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg", native = TRUE)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg", "data/instructor.jpeg")
readJPEG("data/instructor.jpeg", native = TRUE)
pic <- readJPEG("data/instructor.jpeg", native = TRUE)
quantile(pic, probs=0.8)
quantile(readJPEG("data/instructor.jpeg", native = TRUE), probs = 80)
quantile(readJPEG("data/instructor.jpeg", native = TRUE), probs = .80)
quantile(readJPEG("data/instructor.jpeg", native = TRUE), probs = .30)
pic <- readJPEG("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg", native = TRUE)
?readJPEG
quantile(pic, probs=0.8)
?quantile
pic
pic <- readJPEG("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg", native = TRUE)
pic <- readJPEG("data/instructor.jpeg", native = TRUE)
pic <- readJPEG("data/instructor.jpg", native = TRUE)
quantile(pic, probs=0.8)
quantile(pic, probs=0.3)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv", "data/gdp.csv")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv", "data/edu.csv")
gdp = read.csv("data/gdp.csv")
edu = read.csv("data/edu.csv")
blah <- merge(gdp, edu, by="id")
View(gdp)
View(gdp)
View(edu)
blah <- merge(gdp, edu, by.x = X, by.y= "CountryCode")
blah <- merge(gdp, edu, by.x = "X", by.y= "CountryCode")
View(blah)
View(gdp)
count(unique(blah$X))
length(unique(blah$X))
?unique
?merge
View(blah)
blah <- merge(gdp, edu, by.x = "X", by.y= "CountryCode", all= TRUE)
length(unique(blah$X))
arrange(blah, Gross.domestic.product.2012)
blah <- arrange(blah, Gross.domestic.product.2012)
filter(blah, !is.na(X))
View(gdp)
gdp = read.csv("data/gdp.csv", skip = 4)
View(edu)
blah <- merge(gdp, edu, by.x = "X", by.y= "CountryCode")
View(blah)
View(gdp)
View(edu)
gdp <- filter(gdp, !is.na(X))
edu <- filter(edu, !is.na(CountryCode))
blah <- merge(gdp, edu, by.x = "X", by.y= "CountryCode")
View(blah)
length(unique(gdp$X.1))
length(unique(gdp$X))
length(unique(edu$CountryCode))
blah <- merge(gdp, edu, by.x = "X", by.y= "CountryCode", all=FALSE)
blah <- merge(gdp, edu, by.x = "X.3", by.y= "Short.Name", all=FALSE)
View(blah)
View(gdp)
blah <- arrange(blah, X.4)
View(blah)
gdp = read.csv("data/gdp.csv")
View(gdp)
gdp = read.csv("data/gdp.csv",header = TRUE)
gdp = read.csv("data/gdp.csv",skip=2,header = TRUE)
gdp = read.csv("data/gdp.csv",skip=3,header = TRUE)
gpd = filter(gdp, !is.na(X))
View(gdp)
gpd <- filter(gdp, !is.na(X))
gdp <- filter(gdp, !is.na(X))
gdp <- gdp[1:216,]
gdp <- gdp[2:216,]
gdp <- gdp[, c(1,2,4,5)]
blah <- merge(gdp, edu, by.x = "Economy", by.y= "Short.Name", all=FALSE)
View(blah)
blah <- arrange(blah, US.dollars.)
blah$US.dollars. <- as.numeric(blah$US.dollars.)
blah <- merge(gdp, edu, by.x = "Economy", by.y= "Short.Name", all=FALSE)
blah$US.dollars. <- as.numeric(gsub(",","",blah$US.dollars.))
filter(blah, is.na(US.dollars.))
filter(blah, !is.na(Ranking))
blah <- filter(blah, is.na(US.dollars.))
blah <- merge(gdp, edu, by.x = "Economy", by.y= "Short.Name", all=FALSE)
blah$US.dollars. <- as.numeric(gsub(",","",blah$US.dollars.))
blah <- filter(blah, !is.na(US.dollars.))
blah <- merge(gdp, edu, by.x = "Economy", by.y= "Short.Name", all=FALSE)
blah <- filter(blah, !is.na(US.dollars.))
blah$US.dollars. <- as.numeric(gsub(",","",blah$US.dollars.))
arrange(blah, US.dollars.)
blah <- arrange(blah, US.dollars.)
edu <- filter(edu, !is.na(Short.Name))
blah <- merge(gdp, edu, by.x = "Economy", by.y= "Short.Name", all=FALSE)
blah$US.dollars. <- as.numeric(gsub(",","",blah$US.dollars.))
blah <- arrange(blah, US.dollars.)
View(blah)
blah <- group_by(blah, Income.Group)
summary(blah, sum(US.dollars.))
summarise(blah, sum(US.dollars.))
summarise(blah, sum(US.dollars., na.rm = TRUE))
summarise(blah, mean(Ranking, na.rm = TRUE))
blah$Ranking <- as.numeric(blah$Ranking)
summarise(blah, mean(Ranking, na.rm = TRUE))
?cut
blah <- mutate(rankings_group = blah,cut(blah$Ranking, breaks=5))
blah <- mutate(blah, rankings_group = blah,cut(blah$Ranking, breaks=5))
ungroup(blah)
blah <- mutate(blah, rankings_group = blah,cut(blah$Ranking, breaks=5))
blah
?mutate
blah <- mutate(blah, rankings_group = cut(blah$Ranking, breaks=5))
rankings_group = cut(blah$Ranking, breaks=5)
length(rankings_group)
blah["rankings_group"] <- rankings_group
group_by(blah, rankings_group)
blah <- group_by(blah, rankings_group)
summarize(blah, Ranking>=38)
summarize(blah, sum(Ranking>=38))
summarize(blah, sum(Income.Group =="Lower middle income")
)
View(gpd)
?rm
rm(gdp)
rm(blah)
rm(edu)
rm(gpd)
source("Getting and Cleaning Data/week3.R")
source("Getting and Cleaning Data/week3.R")
View(gdp)
source("Getting and Cleaning Data/week3.R")
View(gdp)
View(edu)
source("Getting and Cleaning Data/week3.R")
source("Getting and Cleaning Data/week3.R")
View(gdp)
source("Getting and Cleaning Data/week3.R")
source("Getting and Cleaning Data/week3.R")
View(gdp)
source("Getting and Cleaning Data/week3.R")
View(gdp)
source("Getting and Cleaning Data/week3.R")
View(gdp)
source("Getting and Cleaning Data/week3.R")
View(Gedu)
source("Getting and Cleaning Data/week3.R")
View(Gedu)
source("Getting and Cleaning Data/week3.R")
View(Gedu)
source("Getting and Cleaning Data/week3.R")
source("Getting and Cleaning Data/week3.R")
Income.Group
IncomeGroup
?mean
source("Getting and Cleaning Data/week3.R")
IncomeGroup
Gedu[`Income Group` == "High income: OECD"
, lapply(.SD, mean)
, .SDcols = c("Rank")
, by = "Income.Group"]
source("Getting and Cleaning Data/week3.R")
source("Getting and Cleaning Data/week3.R")
source("Getting and Cleaning Data/week3.R")
mergedDF[-13,]
mergedDF[13,.(Economy)]
mergedDF[13,]
mergedDF[13, "Economy"]
View(mergedDF)
source("Getting and Cleaning Data/week3.R")
source("Getting and Cleaning Data/week3.R")
source("Getting and Cleaning Data/week3.R")
mergedDT[`Income Group` == "Lower middle income", .N, by = c("Income Group", "quantileGDP")]
source("Getting and Cleaning Data/week3.R")
nrow(mergedDT)
source("Getting and Cleaning Data/week3.R")
mergedDT[`Income Group` == "Lower middle income", .N, by = c("Income Group", "quantileGDP")]
nrow(mergedDT)
View(mergedDT)
mergedDT[order(-Rank)][13,.(Economy)]
mergedDT[`Income Group` == "High income: OECD"
, lapply(.SD, mean)
, .SDcols = c("Rank")
, by = "Income Group"]
grouped = group_by(mergedDT, "Income.Group")
summarize(grouped, mean(Eanking))
summarize(grouped, mean(Ranking))
grouped = group_by(mergedDT, "Income Group")
summarize(grouped, mean(Ranking))
summarize(grouped, mean(Rank, na.rm= TRUE))
grouped
grouped = group_by(mergedDT, Income Group)
grouped = group_by(mergedDT, mergedDT["Income Group"])
grouped
grouped = group_by(mergedDT, "Income Group")
grouped
# Download data and read FGDP data into data.table
FGDP <- data.table::fread('https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
, skip=4
, nrows = 190
, select = c(1, 2, 4, 5)
, col.names=c("CountryCode", "Rank", "Economy", "Total")
)
# Download data and read FGDP data into data.table
FEDSTATS_Country <- data.table::fread('https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
)
mergedDT <- merge(FGDP, FEDSTATS_Country, by = 'CountryCode')
View(mergedDT)
grouped <- group_by(mergedDT, "Income Group")
View(grouped)
summarize(grouped, mean(Rank, na.rm= TRUE))
grouped <- group_by(mergedDT, mergedDT["Income Group"])
View(grouped)
grouped <- mergedDT %>% group_by(Income Group)
?fread
source("Getting and Cleaning Data/week3.R")
source("Getting and Cleaning Data/week3.R")
View(FGDP)
source("Getting and Cleaning Data/week3.R")
View(FGDP)
source("Getting and Cleaning Data/week3.R")
View(mergedDT)
source("Getting and Cleaning Data/week3.R")
source("Getting and Cleaning Data/week3.R")
View(mergedDT)
source("Getting and Cleaning Data/week3.R")
View(grouped)
source("Getting and Cleaning Data/week3.R")
View(FGDP)
View(grouped)
source("Getting and Cleaning Data/week3.R")
View(mean_grouped)
View(grouped)
source("Getting and Cleaning Data/week3.R")
?cut
source("Getting and Cleaning Data/week3.R")
source("Getting and Cleaning Data/week3.R")
cut_grouped
source("Getting and Cleaning Data/week3.R")
group_by()
grouped
cut_grouped
source("Getting and Cleaning Data/week3.R")
cut_grouped
source("Getting and Cleaning Data/week3.R")
cut_grouped
source("Getting and Cleaning Data/week3.R")
cut_grouped
source("Getting and Cleaning Data/week3.R")
cut_grouped
?t.test
source("Statistical Inference/week3.R")
source("Statistical Inference/week3.R")
source("Statistical Inference/week3.R")
source("Statistical Inference/week3.R")
source("Statistical Inference/week3.R")
source("Statistical Inference/week3.R")
library(tidyverse)
names <- c("a", "b", "c", "d")
age <- c(2,3 ,4 ,5 )
people <- data.frame(names, age)
head(people)
str(people)
glimpse(people)
mutate(people, age_in_20 = age + 20)
install.packages("Tmisc")
library('Tmisc')
library(Tmisc)
library('Tmisc')
data("quartet")
view(quartet)
library('Tmisc')
data("quartet")
View(quartet)
quartet %>%
group_by(set) %>%
summarize(mean(x), sd(x), mean(y), sd(y), cor(x,y))
library(dbplyr)
library(tidyr)
quartet %>%
group_by(set) %>%
summarize(mean(x), sd(x), mean(y), sd(y), cor(x,y))
quartet %>%
group_by(set) %>%
summarise(mean(x), sd(x), mean(y), sd(y), cor(x,y))
library(dplyr)
quartet %>%
group_by(set) %>%
summarise(mean(x), sd(x), mean(y), sd(y), cor(x,y))
install.packages('datasauRus')
library('datasauRus')
install.packages("SimDesign")
library("SimDesign")
?summarize
?unite
str(quartet)
dir
dir()
dir("D:\GitHub\getting_and_cleaning_data")
dir("D:\\GitHub\getting_and_cleaning_data")
dir("D:\\GitHub\\getting_and_cleaning_data")
setwd("D:/GitHub/getting_and_cleaning_data")
download.file
if(!dir("/data")){dir.create("/data")}
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip","/data")
if(!dir.exists("/data")){dir.create("/data")}
dir.("/data")
dir.exists("/data")
if(!dir.exists("/data")){dir.create("/data")}
if(!dir.exists("\data")){dir.create("\data")}
if(!dir.exists("/data")){dir.create("/data")}
dir.create("/data")
setwd("D:/GitHub/getting_and_cleaning_data")
dir.create("/data")
getwd()
dir.create("data")
if(!dir.exists("data")){dir.create("data")}
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip","data")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip","/data")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip","data/activity.zip")
unzip("data/activity.zip")
?unzip
unzip("data/activity.zip", exdir="data")
setwd("/UCI HAR Dataset")
setwd("/UCI\ HAR\ Dataset")
file.read("/UCI HAR Dataset/test/X_test.txt")
read.delim("/UCI HAR Dataset/test/X_test.txt", header=FALSE)
read.delim("/data/UCI HAR Dataset/test/X_test.txt", header=FALSE)
read.delim("data/UCI HAR Dataset/test/X_test.txt", header=FALSE)
data <- read.delim("data/UCI HAR Dataset/test/X_test.txt", header=FALSE)
View(data)
?read.delim2
data <- read.delim("data/UCI HAR Dataset/test/X_test.txt", header=FALSE, sep = " ")
View(data)
library(tidyverse)
View(data)
data <- read_delim("data/UCI HAR Dataset/test/X_test.txt")
View(data)
?read_delim
factor_names <- read_delim("data/UCI HAR Dataset/features.txt", col_names =c("factor", "variables"))
View(factor_names)
View(factor_names)
View(factor_names)
y_test <- read_delim("data/UCI HAR Dataset/test/y_test.txt")
rm("data")
rm("factor_names")
